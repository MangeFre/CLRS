## 3.1-1

> Let $f(n) + g(n)$ be asymptotically nonnegative functions. Using the basic definition of $\Theta$-notation, prove that $\max(f(n), g(n)) = \Theta(f(n) + g(n))$.

(Removed)

## 3.1-2

> Show that for any real constants $a$ and $b$, where $b > 0$,
>
> $$(n + a)^b = \Theta(n^b). \tag{3.2}$$

(Removed)

## 3.1-3

> Explain why the statement, "The running time of algorithm $A$ is at least $O(n^2)$," is meaningless.

(Removed)

## 3.1-4

> Is $2^{n + 1} = O(2^n)$? Is $2^{2n} = O(2^n)$?

(Removed)

## 3.1-5

> Prove Theorem 3.1.

The theorem states:

> For any two functions $f(n)$ and $g(n)$, we have $f(n) = \Theta(g(n))$ if and only if $f(n) = O(g(n))$ and $f(n) = \Theta(g(n))$.

From $f = \Theta(g(n))$, we have that

$$0 \le c_1 g(n) \le f(n) \le c_2g(n) \text{ for } n > n_0.$$

We can pick the constants from here and use them in the definitions of $O$ and $\Omega$ to show that both hold.

From $f(n) = \Omega(g(n))$ and $f(n) = O(g(n))$, we have that

$$
\begin{aligned}
            & 0 \le c_3g(n) \le f(n) & \text{ for all } n \ge n_1 \\\\
\text{and } & 0 \le f(n) \le c_4g(n) & \text{ for all } n \ge n_2.
\end{aligned}
$$

If we let $n_3 = \max(n_1, n_2)$ and merge the inequalities, we get

$$0 \le c_3g(n) \le f(n) \le c_4g(n) \text{ for all } n > n_3.$$

Which is the definition of $\Theta$.

## 3.1-6

> Prove that the running time of an algorithm is $\Theta(g(n))$ if and only if its worst-case running time is $O(g(n))$ and its best-case running time is $\Omega(g(n))$.

If $T_w$ is the worst-case running time and $T_b$ is the best-case running time, we know that

$$
\begin{aligned}
            & 0 \le c_1g(n) \le T_b(n) & \text{ for } n > n_b \\\\
\text{and } & 0 \le T_w(n) \le c_2g(n) & \text{ for } n > n_w.
\end{aligned}
$$

Combining them we get

$$0 \le c_1g(n) \le T_b(n) \le T_w(n) \le c_2g(n) \text{ for } n > \max(n_b, n_w).$$

Since the running time is bound between $T_b$ and $T_w$ and the above is the definition of the $\Theta$-notation, proved.

## 3.1-7

> Prove $o(g(n)) \cap w(g(n))$ is the empty set.

We know that for any $c > 0$,

$$
\begin{aligned}
            & \exists n_1 > 0: 0 \le f(n) < cg(n) \\\\
\text{and } & \exists n_2 > 0: 0 \le cg(n) < f(n).
\end{aligned}
$$

If we pick $n_0 = \max(n_1, n_2)$, from the problem definition we get

$$f(n) < cg(n) < f(n).$$

There is no solutions, which means that the intersection is the empty set.

## 3.1-8

> We can extend our notation to the case of two parameters $n$ and $m$ that can go to infinity independently at different rates. For a given function $g(n, m)$ we denote $O(g(n, m))$ the set of functions:
>
> $$
> \begin{aligned}
> O(g(n, m)) = \\{f(n, m):
>   & \text{ there exist positive constants } c, n_0, \text{ and } m_0 \\\\
>   & \text{ such that } 0 \le f(n, m) \le cg(n, m) \\\\
>   & \text{ for all } n \ge n_0 \text{ or } m \ge m_0.\\}
> \end{aligned}
> $$
>
> Give corresponding definitions for $\Omega(g(n, m))$ and $\Theta(g(n, m))$.

(Removed)
